{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd85823",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6363cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "\n",
    "from torchtext.data import utils\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1198271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AbstractDataset\n",
    "from snn_util import AbstractSNN_1, SpikingBCELoss, train_model, forward_pass\n",
    "from util import load_model_and_opt, save_model, batch_predict, load_from_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19da662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = (f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "HOME = '/home/hice1/khom9/CSE 8803 BMI Final Project'\n",
    "CNN_VERSION = 2\n",
    "SNN_VERSION = 6\n",
    "# Path to the saved word embeddings file\n",
    "EMBED_KEYS_PATH = f'{HOME}/wordvectors/abstracts200_trained_normalized_{CNN_VERSION}.wordvectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfff41b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "print(f'Using device {DEVICE}')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1749bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 23250/23250 [00:15<00:00, 1502.13it/s]\n"
     ]
    }
   ],
   "source": [
    "tk = utils.get_tokenizer('spacy') # use spacey tokenizer\n",
    "wv = gensim.models.KeyedVectors.load(EMBED_KEYS_PATH, mmap='r') # Get the saved word vectors matrix\n",
    "null_word = '\\0' # Will be used to pad all abstracts to the same length (669 words)\n",
    "d = AbstractDataset(f'{HOME}/CleanedAVdata.csv', 'Abstract', 'IPCR Classifications', tk, wv.key_to_index,\n",
    "                    null_word=null_word, min_len=30, verbose=True) # PyTorch dataset for abstracts & their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de0f1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "beta = 1.0\n",
    "lr = 1e-5\n",
    "T = 45\n",
    "\n",
    "save_path = f'{HOME}/models/snn_model-{SNN_VERSION}.pth'\n",
    "cnn_path = f'{HOME}/models/cnn_model-{CNN_VERSION}.pth'\n",
    "cnn_act_path = f'{HOME}/models/cnn_model-{CNN_VERSION}-max-activations.pkl'\n",
    "\n",
    "loader = DataLoader(d, batch_size=batch_size, shuffle=True)\n",
    "model = AbstractSNN_1(T, EMBED_KEYS_PATH, null_word=null_word, beta=beta).to(DEVICE)\n",
    "\n",
    "# Create a positive weight, such that we punish the model heavily for guessing 0 all the time.\n",
    "num_pos = d.labels.sum(axis=0, keepdim=True)\n",
    "pos_weight = (d.labels.shape[0] - num_pos) / num_pos\n",
    "loss_fn = SpikingBCELoss(pos_weight=pos_weight.squeeze().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312c1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this line if training from scratch:\n",
    "# model = load_from_cnn(model, cnn_path, cnn_act_path)\n",
    "\n",
    "optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "# Uncomment the following lines if resuming training:\n",
    "# model, optimizer = load_model_and_opt(model, optimizer, save_path)\n",
    "# for g in optimizer.param_groups:\n",
    "#     g['lr'] = lr\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b74df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 350\n",
    "# train_model(model, optimizer, d, loss_fn, T=T, epochs=epochs, batch_size=batch_size, save_freq=10, save_path=save_path,\n",
    "#             scheduler=scheduler, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77383765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(save_path, model, optimizer, epochs)\n",
    "# print(f'Saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "005e1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = batch_predict(model, d.abst_data, T=T, fw_pass_fn=forward_pass, device=DEVICE)\n",
    "pred_spk = ((pred.mean(dim=0)) > 0.5).type(torch.float)\n",
    "true = d.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b88df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total avg loss: 2.063510634458193\n"
     ]
    }
   ],
   "source": [
    "total_loss = []\n",
    "loss_fn_cpu = loss_fn.to('cpu')\n",
    "for i in range(len(d)):\n",
    "    total_loss.append(loss_fn_cpu(pred_spk[i].unsqueeze(0), true[i]).item())\n",
    "    \n",
    "print(f'Total avg loss: {np.mean(total_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489623e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5958837270736694\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [7.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [8.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [1.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [2.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [3.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [4.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [5.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [6.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.0000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.1000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.4000e+01, 9.3333e-01, 1.0000e+00],\n",
      "        [7.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [7.8000e+01, 7.7778e-01, 1.0000e+00],\n",
      "        [7.9000e+01, 7.5556e-01, 1.0000e+00],\n",
      "        [8.0000e+01, 1.5556e-01, 0.0000e+00],\n",
      "        [8.1000e+01, 2.2222e-02, 0.0000e+00],\n",
      "        [8.2000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.3000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.4000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.5000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.6000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.7000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.8000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [8.9000e+01, 0.0000e+00, 0.0000e+00],\n",
      "        [9.0000e+01, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Print a sample prediction and true label\n",
    "i =18722\n",
    "txt, label = d[i]\n",
    "# txt = txt.unsqueeze(0)\n",
    "loss_fn = loss_fn.to(DEVICE)\n",
    "label = label.unsqueeze(0)\n",
    "\n",
    "print(loss_fn(forward_pass(model, T, txt.to(DEVICE)).detach(), label.to(DEVICE)).item())\n",
    "print(torch.cat([torch.tensor([list(range(91))]).to(DEVICE),                  # Index\n",
    "                 forward_pass(model, T, txt.to(DEVICE)).mean(dim=0).detach(), # Prediction \n",
    "                 label.to(DEVICE)]).T)                                        # True label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "421cdd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63926941 0.16666667 0.48       0.83333333 1.         0.5\n",
      " 0.66666667 0.76566125 0.68250951 0.52       0.78512397 0.44680851\n",
      " 0.5        0.63829787 0.55555556 0.14285714 0.43697479 0.53846154\n",
      " 1.         0.5        0.70138889 0.5        0.85714286 0.5\n",
      " 0.48979592 0.5        0.57894737 0.72222222 0.5        0.33333333\n",
      " 0.88837438 0.67123288 0.69288577 0.57391304 0.65938865 0.64976959\n",
      " 0.74242424 0.30555556 0.4        0.71428571 0.375      1.\n",
      " 0.26315789 1.         0.75       0.40909091 0.5        1.\n",
      " 0.5        0.28571429 0.28571429 1.         0.56521739 0.64179104\n",
      " 0.62903226 0.5        0.5        0.50657895 0.46153846 0.47619048\n",
      " 0.72340426 0.74846626 0.61538462 0.62962963 0.4375     0.59459459\n",
      " 0.75       0.64705882 0.44       0.59259259 1.         0.37037037\n",
      " 0.35483871 0.5        0.79847278 0.69577465 0.46226415 0.74074074\n",
      " 0.82828729 0.88735949 0.74204545 0.77896696 0.61835749 0.74789916\n",
      " 0.55       0.58878505 0.65131579 0.71428571 0.64705882 0.83638211\n",
      " 0.71653543]\n",
      "Total precision: 0.8246582750392346\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(true, pred_spk, average=None))\n",
    "print(f'Total precision: {precision_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0f13d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98591549 1.         1.         1.         1.         1.\n",
      " 1.         0.97345133 1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.98058252 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.74385415 1.         0.96645702 1.         0.97106109 0.96575342\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         0.97727273\n",
      " 1.         1.         0.95918367 1.         1.         1.\n",
      " 1.         0.98387097 1.         1.         1.         0.99435028\n",
      " 1.         1.         1.         0.84210526 1.         1.\n",
      " 1.         1.         0.89872945 0.97244094 1.         1.\n",
      " 0.78311743 0.90479532 0.97172619 0.94763657 0.99610895 0.98342541\n",
      " 1.         0.94029851 0.99497487 0.98920863 1.         0.94516222\n",
      " 0.95789474]\n",
      "Total recall: 0.8590492908579521\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(true, pred_spk, average=None))\n",
    "print(f'Total recall: {recall_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05dd4d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total F1 score: 0.8345685388269651\n"
     ]
    }
   ],
   "source": [
    "print(f'Total F1 score: {f1_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6710a673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b65aa81",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
