{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4db4fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "549609f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import OrderedDict\n",
    "from torch import nn, optim\n",
    "from torchtext.data import utils\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbf3b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AbstractDataset\n",
    "from util import save_model, load_model_and_opt, batch_predict\n",
    "from cnn_util import CNNBase2, train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ef00680",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = (f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "HOME = '/home/hice1/khom9/CSE 8803 BMI Final Project'\n",
    "EMBED_KEYS_PATH = f'{HOME}/wordvectors/abstracts200_normalized.wordvectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f1249c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type of CNN (1, 2, or 3); refer to cnn_util.py for more info\n",
    "VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d11360d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:0\n",
      "NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "print(f'Using device {DEVICE}')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9b06e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom nltk.stem import WordNetLemmatizer\\nimport nltk\\nfrom gensim.models import Word2Vec\\n\\n\\ndf = pd.read_csv('CleanedAVdata.csv')\\nnltk.download('wordnet')\\ntk = utils.get_tokenizer('spacy')\\nlemma = WordNetLemmatizer()\\nabstracts = df['Abstract']\\nembed_dim = 200\\ntokens = pd.Series([[lemma.lemmatize(w) for w in tk(abst)] for abst in abstracts])\\nmodel = Word2Vec(sentences=tokens, vector_size=embed_dim, window=5, min_count=1, workers=12)\\n\\nmu = np.mean(model.wv.vectors)\\nsigma = np.sqrt(np.var(model.wv.vectors))\\nmodel.wv.vectors = (1 + (np.clip(model.wv.vectors, mu-3*sigma, mu+3*sigma) - mu) / (3*sigma)) / 2\\nmodel.wv.vectors = np.clip(model.wv.vectors, 0, 1)\\n\\nmodel.wv['\\x00'] = np.zeros(embed_dim)\\nmodel.wv.save(f'{HOME}/wordvectors/abstracts{embed_dim}_normalized.wordvectors')\\n\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only run once\n",
    "\n",
    "'''\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "df = pd.read_csv('CleanedAVdata.csv')\n",
    "nltk.download('wordnet')\n",
    "tk = utils.get_tokenizer('spacy')\n",
    "lemma = WordNetLemmatizer()\n",
    "abstracts = df['Abstract']\n",
    "embed_dim = 200\n",
    "tokens = pd.Series([[lemma.lemmatize(w) for w in tk(abst)] for abst in abstracts])\n",
    "model = Word2Vec(sentences=tokens, vector_size=embed_dim, window=5, min_count=1, workers=12)\n",
    "\n",
    "mu = np.mean(model.wv.vectors)\n",
    "sigma = np.sqrt(np.var(model.wv.vectors))\n",
    "model.wv.vectors = (1 + (np.clip(model.wv.vectors, mu-3*sigma, mu+3*sigma) - mu) / (3*sigma)) / 2\n",
    "model.wv.vectors = np.clip(model.wv.vectors, 0, 1)\n",
    "\n",
    "model.wv['\\0'] = np.zeros(embed_dim)\n",
    "model.wv.save(f'{HOME}/wordvectors/abstracts{embed_dim}_normalized.wordvectors')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b8654b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n",
      "100%|██████████| 23250/23250 [00:13<00:00, 1763.58it/s]\n"
     ]
    }
   ],
   "source": [
    "tk = utils.get_tokenizer('spacy')\n",
    "wv = gensim.models.KeyedVectors.load(EMBED_KEYS_PATH, mmap='r')\n",
    "null_word = '\\0'\n",
    "d = AbstractDataset('CleanedAVdata.csv', 'Abstract', 'IPCR Classifications', tk, wv.key_to_index,\n",
    "                    null_word=null_word, min_len=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fa7bf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "batch_size = 48\n",
    "model = CNNBase2(EMBED_KEYS_PATH, null_word=null_word).to(DEVICE)\n",
    "\n",
    "save_path = f'{HOME}/models/cnn_model-{VERSION}.pth'\n",
    "act_path = f'{HOME}/models/cnn_model-{VERSION}-max-activations.pkl'\n",
    "wv_out_path = f'{HOME}/wordvectors/abstracts200_trained_normalized_{VERSION}.wordvectors'\n",
    "\n",
    "num_pos = d.labels.sum(axis=0, keepdim=True).to_dense()\n",
    "pos_weight = (d.labels.shape[0] - num_pos) / num_pos\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(DEVICE))\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# model, optimizer = load_model_and_opt(model, optimizer, f'{HOME}/models/cnn_model-4.pth')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffe5e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 1.6806999999999997e-05\n",
      "Scheduler: <torch.optim.lr_scheduler.StepLR object at 0x15542d73dbd0>\n",
      "Training for 100 epochs, with batch size=48\n",
      "Using device: cuda:0\n",
      "Saving model every 25 epochs to /home/hice1/khom9/CSE 8803 BMI Final Project/models/cnn_model-999.pth\n",
      "\n",
      "-----Epoch 1/100-----\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CSE 8803 BMI Final Project/cnn_util.py:180\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, dataset, loss_fn, epochs, batch_size, save_freq, save_path, scheduler, device)\u001b[0m\n\u001b[1;32m    178\u001b[0m txt \u001b[38;5;241m=\u001b[39m txt\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m    179\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(txt)\n\u001b[0;32m--> 180\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    182\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:725\u001b[0m, in \u001b[0;36mBCEWithLogitsLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m                                              \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m                                              \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3197\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[1;32m   3195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 3197\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "train_model(model, optimizer, d, loss_fn, epochs=epochs, batch_size=batch_size, save_freq=None, \n",
    "            save_path=save_path, scheduler=scheduler, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e6ef550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_model(save_path, model, optimizer, epochs)\n",
    "# print(f'Saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a0c335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02605363354086876\n",
      "tensor([[-6.0868e+00,  0.0000e+00],\n",
      "        [-2.9881e+02,  0.0000e+00],\n",
      "        [-7.8192e+01,  0.0000e+00],\n",
      "        [-3.0177e+02,  0.0000e+00],\n",
      "        [-1.9628e+02,  0.0000e+00],\n",
      "        [-2.7280e+02,  0.0000e+00],\n",
      "        [-2.6021e+02,  0.0000e+00],\n",
      "        [-6.9971e+00,  0.0000e+00],\n",
      "        [-3.0986e+01,  0.0000e+00],\n",
      "        [-1.9503e+02,  0.0000e+00],\n",
      "        [-3.0685e+01,  0.0000e+00],\n",
      "        [-6.6394e+01,  0.0000e+00],\n",
      "        [-1.7377e+02,  0.0000e+00],\n",
      "        [-7.1118e+01,  0.0000e+00],\n",
      "        [-2.3271e+02,  0.0000e+00],\n",
      "        [-3.3649e+02,  0.0000e+00],\n",
      "        [-8.4957e+01,  0.0000e+00],\n",
      "        [-2.7943e+02,  0.0000e+00],\n",
      "        [-4.3802e+02,  0.0000e+00],\n",
      "        [-1.4315e+02,  0.0000e+00],\n",
      "        [-6.1936e+00,  0.0000e+00],\n",
      "        [-5.3692e+02,  0.0000e+00],\n",
      "        [-3.6010e+02,  0.0000e+00],\n",
      "        [-4.5273e+02,  0.0000e+00],\n",
      "        [-1.9372e+02,  0.0000e+00],\n",
      "        [-5.3827e+02,  0.0000e+00],\n",
      "        [-3.0033e+02,  0.0000e+00],\n",
      "        [-6.9804e+01,  0.0000e+00],\n",
      "        [-2.9026e+02,  0.0000e+00],\n",
      "        [-3.4762e+02,  0.0000e+00],\n",
      "        [-1.0677e+00,  0.0000e+00],\n",
      "        [-7.7619e+01,  0.0000e+00],\n",
      "        [-1.9118e+00,  0.0000e+00],\n",
      "        [-2.2241e+01,  0.0000e+00],\n",
      "        [-5.3357e+00,  0.0000e+00],\n",
      "        [-5.0907e+01,  0.0000e+00],\n",
      "        [-2.4435e+01,  0.0000e+00],\n",
      "        [-1.5348e+02,  0.0000e+00],\n",
      "        [-2.6077e+02,  0.0000e+00],\n",
      "        [-4.3894e+02,  0.0000e+00],\n",
      "        [-3.1696e+02,  0.0000e+00],\n",
      "        [-2.9863e+02,  0.0000e+00],\n",
      "        [-3.3527e+02,  0.0000e+00],\n",
      "        [-5.2500e+02,  0.0000e+00],\n",
      "        [-2.6569e+02,  0.0000e+00],\n",
      "        [-2.0586e+02,  0.0000e+00],\n",
      "        [-3.4768e+02,  0.0000e+00],\n",
      "        [-6.3573e+02,  0.0000e+00],\n",
      "        [-3.1862e+02,  0.0000e+00],\n",
      "        [-6.1900e+02,  0.0000e+00],\n",
      "        [-5.0053e+02,  0.0000e+00],\n",
      "        [-3.9077e+02,  0.0000e+00],\n",
      "        [-1.6481e+02,  0.0000e+00],\n",
      "        [-4.1916e+01,  0.0000e+00],\n",
      "        [-5.8728e+01,  0.0000e+00],\n",
      "        [-3.4219e+02,  0.0000e+00],\n",
      "        [-2.4937e+01,  0.0000e+00],\n",
      "        [-3.5752e+01,  0.0000e+00],\n",
      "        [-9.6402e+01,  0.0000e+00],\n",
      "        [-1.1769e+02,  0.0000e+00],\n",
      "        [-2.8465e+01,  0.0000e+00],\n",
      "        [-4.4130e+01,  0.0000e+00],\n",
      "        [-1.4189e+02,  0.0000e+00],\n",
      "        [-8.6049e+01,  0.0000e+00],\n",
      "        [-3.0568e+02,  0.0000e+00],\n",
      "        [-8.4862e+00,  0.0000e+00],\n",
      "        [-3.4739e+02,  0.0000e+00],\n",
      "        [-5.3456e+01,  0.0000e+00],\n",
      "        [-6.1857e+01,  0.0000e+00],\n",
      "        [-1.6288e+02,  0.0000e+00],\n",
      "        [-4.6829e+02,  0.0000e+00],\n",
      "        [-2.9608e+02,  0.0000e+00],\n",
      "        [-6.5415e+01,  0.0000e+00],\n",
      "        [-5.2933e+02,  0.0000e+00],\n",
      "        [ 6.0431e-01,  0.0000e+00],\n",
      "        [-1.2133e+01,  0.0000e+00],\n",
      "        [ 8.6633e+00,  1.0000e+00],\n",
      "        [-9.2268e+01,  0.0000e+00],\n",
      "        [ 9.4590e-02,  0.0000e+00],\n",
      "        [-2.8922e+00,  0.0000e+00],\n",
      "        [-1.1628e+01,  0.0000e+00],\n",
      "        [-7.1079e+00,  0.0000e+00],\n",
      "        [-4.0295e+01,  0.0000e+00],\n",
      "        [-3.6620e+01,  0.0000e+00],\n",
      "        [-8.3569e+01,  0.0000e+00],\n",
      "        [-6.1975e+01,  0.0000e+00],\n",
      "        [-2.7719e+01,  0.0000e+00],\n",
      "        [-4.8115e+00,  0.0000e+00],\n",
      "        [-5.3003e+01,  0.0000e+00],\n",
      "        [-7.2487e+00,  0.0000e+00],\n",
      "        [-2.9379e+01,  0.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "i = 8721 #18622\n",
    "txt, label = d[i]\n",
    "label = label.unsqueeze(0)\n",
    "print(loss_fn(model(txt.to(DEVICE)).detach(), label.to(DEVICE)).item())\n",
    "print(torch.cat([model(txt.to(DEVICE)).detach(), label.to(DEVICE)]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e36ea3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (torch.sigmoid(batch_predict(model, d.abst_data, device=DEVICE).detach().cpu()) > 0.5).type(torch.float)\n",
    "true = d.labels.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "831c7a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total avg loss: 0.9919314197212137\n"
     ]
    }
   ],
   "source": [
    "total_loss = []\n",
    "loss_fn_cpu = loss_fn.cpu()\n",
    "for i in range(len(d)):\n",
    "    total_loss.append(loss_fn_cpu(pred[i].unsqueeze(0), true[i].unsqueeze(0)).item())\n",
    "    \n",
    "print(f'Total avg loss: {np.mean(total_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f669161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11919    98.332405\n",
       "130      89.000214\n",
       "2267     87.721077\n",
       "22573    84.880768\n",
       "18414    84.525742\n",
       "17995    84.115845\n",
       "18534    82.558167\n",
       "18548    81.296745\n",
       "21263    80.901932\n",
       "17761    80.785957\n",
       "18622    80.739159\n",
       "18642    80.721985\n",
       "20998    44.534679\n",
       "11239    44.242897\n",
       "18483    41.305679\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.Series(total_loss)\n",
    "x.sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d865e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55252918 1.         0.75       1.         1.         1.\n",
      " 0.43478261 0.63128492 0.59634551 0.8125     0.95       0.65625\n",
      " 1.         0.76923077 0.83333333 1.         0.59770115 0.5\n",
      " 1.         0.57971014 0.60499266 1.         0.66666667 1.\n",
      " 0.58536585 1.         1.         0.86666667 0.5        0.5\n",
      " 0.78249574 0.84482759 0.51039427 0.66666667 0.54946996 0.46056782\n",
      " 0.57309942 1.         1.         1.         0.42857143 1.\n",
      " 0.26315789 1.         0.75       0.9        1.         0.33333333\n",
      " 1.         0.33333333 1.         0.33333333 1.         0.77192982\n",
      " 0.76470588 0.75       0.67123288 0.76237624 0.85714286 0.66666667\n",
      " 0.97142857 0.65263158 1.         0.68       0.7        0.51754386\n",
      " 1.         0.96491228 0.78571429 0.65517241 1.         0.76923077\n",
      " 0.78571429 0.75       0.54318154 0.70555556 0.875      0.95238095\n",
      " 0.67994018 0.71757833 0.56105749 0.51044158 0.69086022 0.80088496\n",
      " 0.84615385 0.79761905 0.72363636 0.52952381 0.77777778 0.62256809\n",
      " 0.73643411]\n",
      "Total precision: 0.6706392843028874\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(true, pred, average=None))\n",
    "print(f'Total precision: {precision_score(true, pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f164fc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 0.79508332 1.         0.99510832 1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.84024664 1.         1.         1.\n",
      " 0.75992478 0.79017544 0.99479167 0.90631192 1.         1.\n",
      " 1.         1.         1.         1.         1.         0.91874821\n",
      " 1.        ]\n",
      "Total recall: 0.8392411880872115\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(true, pred, average=None))\n",
    "print(f'Total recall: {recall_score(true, pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5a9f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7371504904929346\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(true, pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "851d848b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy: 0.28658064516129034\n"
     ]
    }
   ],
   "source": [
    "print(f'Total accuracy: {accuracy_score(true, pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9aec5fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved word embeddings to /home/hice1/khom9/CSE 8803 BMI Final Project/wordvectors/abstracts200_trained_normalized_999.wordvectors\n"
     ]
    }
   ],
   "source": [
    "wv_tuned = gensim.models.KeyedVectors.load(EMBED_KEYS_PATH, mmap='r')\n",
    "wv_tuned.vectors = model.embedding.weight.data.detach().cpu().numpy()\n",
    "\n",
    "wv_tuned.vectors = np.clip(wv_tuned.vectors, a_min=0, a_max=1.)\n",
    "\n",
    "wv_tuned.save(wv_out_path)\n",
    "print(f'Saved word embeddings to {wv_out_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d6160c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote max layer activations to /home/hice1/khom9/CSE 8803 BMI Final Project/models/cnn_model-999-max-activations.pkl\n"
     ]
    }
   ],
   "source": [
    "activations = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for txt, label in (d):\n",
    "        outputs = list(model(txt.to(DEVICE), all_outputs_max=True))\n",
    "        activations.append(outputs)\n",
    "activations = torch.tensor(activations)\n",
    "\n",
    "max_act = torch.max(activations, axis=0)[0]\n",
    "max_act_dict = OrderedDict(zip(list(dict(model.named_modules()).keys())[1:], max_act))\n",
    "\n",
    "output = open(act_path, 'wb')\n",
    "pickle.dump(max_act_dict, output)\n",
    "output.close()\n",
    "print(f'Wrote max layer activations to {act_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a1b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
