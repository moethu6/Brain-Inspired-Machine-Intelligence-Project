{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd85823",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6363cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "from torch import optim\n",
    "from torchtext.data import utils\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1198271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import AbstractDataset\n",
    "from snn_util import AbstractSNN_2, SpikingBCELoss, forward_pass, train_model\n",
    "from util import batch_predict, load_from_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19da662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = (f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "HOME = '/home/hice1/khom9/CSE 8803 BMI Final Project'\n",
    "CNN_VERSION = 6\n",
    "# Path to the saved word embeddings file\n",
    "EMBED_KEYS_PATH = f'{HOME}/wordvectors/abstracts200_trained_normalized_{CNN_VERSION}.wordvectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e956b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Using device {DEVICE}')\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1749bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = utils.get_tokenizer('spacy') # use spacy tokenizer\n",
    "wv = gensim.models.KeyedVectors.load(EMBED_KEYS_PATH, mmap='r') # Get the saved word vectors matrix\n",
    "null_word = '\\0' # Will be used to pad all abstracts to the same length (669 words)\n",
    "d = AbstractDataset(f'{HOME}/CleanedAVdata.csv', 'Abstract', 'IPCR Classifications', tk, wv.key_to_index,\n",
    "                    null_word=null_word, min_len=30, verbose=False) # PyTorch dataset for abstracts & their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0f1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 48\n",
    "beta = 1.0\n",
    "lr = 1e-4\n",
    "T = 45\n",
    "\n",
    "snn_version = 8\n",
    "save_path = f'{HOME}/models/snn_model-{snn_version}.pth'\n",
    "cnn_path = f'{HOME}/models/cnn_model-{CNN_VERSION}.pth'\n",
    "cnn_act_path = f'{HOME}/models/cnn_model-{CNN_VERSION}-max-activations.pkl'\n",
    "\n",
    "model = AbstractSNN_2(T, EMBED_KEYS_PATH, null_word=null_word, beta=beta).to(DEVICE)\n",
    "\n",
    "# Create a positive weight, such that we punish the model heavily for guessing 0 all the time.\n",
    "num_pos = d.labels.sum(axis=0, keepdim=True).to_dense()\n",
    "pos_weight = (d.labels.shape[0] - num_pos) / num_pos\n",
    "loss_fn = SpikingBCELoss(pos_weight=pos_weight.squeeze().to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312c1d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_from_cnn(model, cnn_path, cnn_act_path, num_lif=5, wv=wv)\n",
    "optimizer = optim.NAdam(model.parameters(), lr=lr)\n",
    "# model, optimizer = load_model_and_opt(model, optimizer, save_path)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=150, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b74df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "train_model(model, optimizer, d, loss_fn, T=T, epochs=epochs, batch_size=batch_size, save_freq=25, save_path=save_path,\n",
    "            scheduler=scheduler, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e1cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (batch_predict(model, d.abst_data, T=T, fw_pass_fn=forward_pass, device=DEVICE))\n",
    "pred_spk = ((pred.mean(dim=0)) > 0.5).type(torch.float)\n",
    "true = d.labels.to_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b88df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "total_loss = []\n",
    "loss_fn_cpu = loss_fn.to('cpu')\n",
    "for i in range(len(d)):\n",
    "    total_loss.append(loss_fn_cpu(pred_spk[i].unsqueeze(0), true[i]).item())\n",
    "    \n",
    "print(f'Total avg loss: {np.mean(total_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489623e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample prediction and true label\n",
    "i =18722\n",
    "txt, label = d[i]\n",
    "# txt = txt.unsqueeze(0)\n",
    "loss_fn = loss_fn.to(DEVICE)\n",
    "label = label.unsqueeze(0)\n",
    "\n",
    "print(loss_fn(forward_pass(model, T, txt.to(DEVICE)).detach(), label.to(DEVICE)).item())\n",
    "print(torch.cat([forward_pass(model, T, txt.to(DEVICE)).mean(dim=0).detach(), label.to(DEVICE)]).T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cdd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(precision_score(true, pred_spk, average=None))\n",
    "print(f'Total precision: {precision_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f13d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recall_score(true, pred_spk, average=None))\n",
    "print(f'Total recall: {recall_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total F1 score: {f1_score(true, pred_spk, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca04ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import spikeplot as splt\n",
    "from matplotlib import pyplot as plt\n",
    "spk, mem = forward_pass(model, T, txt.to(DEVICE), return_mem=True)\n",
    "spk, mem = spk.squeeze(), mem.squeeze()\n",
    "splt.traces(mem, spk=spk, dim=(10,9))\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b65aa81",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
